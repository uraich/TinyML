{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to train a neural network for the magic wand "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define filenames for the model files:\n",
    "* The trained TensorFlow model\n",
    "* The quantized flat model that can be used on the micro-controller\n",
    "* finally a C++ file with the model data to be included into an Arduino program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0g1pF6RfViPr"
   },
   "outputs": [],
   "source": [
    "SAVED_MODEL_FILENAME = \"models/saved_model\"\n",
    "FLOAT_TFL_MODEL_FILENAME = \"models/float_model.tfl\"\n",
    "QUANTIZED_TFL_MODEL_FILENAME = \"models/quantized_model.tfl\"\n",
    "TFL_CC_MODEL_FILENAME = \"models/magic_wand_model_data.cc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following shows how to get at the training data  \n",
    "I commented this because the data have already been collected manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvPo0OP0TFDq",
    "outputId": "bd434b10-f2e0-424d-d7d9-b921b0d5eb27"
   },
   "outputs": [],
   "source": [
    "# !curl -L https://github.com/petewarden/magic_wand_digit_data/archive/8170591863f9addca27b1a963263f7c7bed33f41.zip_wand -o magic_digit_data.zip\n",
    "# !unzip magic_wand_digit_data.zip\n",
    "# !rm -rf magic_wand_digit_data\n",
    "# !mv magic_wand_digit_data-* magic_wand_digit_data\n",
    "# !rm -rf magic_wand_digit_data.zip\n",
    "# !rm -rf sample_data\n",
    "# !mkdir -p checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'new_petewarden'...\n",
      "remote: Enumerating objects: 33, done.\u001b[K\n",
      "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
      "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
      "remote: Total 33 (delta 22), reused 28 (delta 20), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (33/33), 775.16 KiB | 3.38 MiB/s, done.\n",
      "Resolving deltas: 100% (22/22), done.\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/petewarden/magic_wand_digit_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the json file and converting it into a list of dictionaries  \n",
    "First the json data a read into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "filename = \"magic_wand_digit_data/petewarden_0.json\"\n",
    "with open(filename, \"r\") as file:\n",
    "    file_contents = file.read()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(file_contents)\n",
    "print(type(file_contents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "json.loads converts the string into a Python dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_data = json.loads(file_contents)\n",
    "print(file_data)\n",
    "print(type(file_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pete Warden's original notebook this is how he reads the json files  \n",
    "There is a total of 10 files for the 10 digits, each containing 100 strokes. In Pete's version the files are read randomly.  \n",
    "Use only one of the two versions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mWO58-igVFSd"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "\n",
    "strokes = []\n",
    "for filename in glob.glob(\"magic_wand_digit_data/*.json\"):\n",
    "  with open(filename, \"r\") as file:\n",
    "    file_contents = file.read()           # reads the file into a string\n",
    "  file_data = json.loads(file_contents)   # converts the json string into a Python dictionary\n",
    "  for stroke in file_data[\"strokes\"]:\n",
    "    stroke[\"filename\"] = filename\n",
    "    strokes.append(stroke)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to figure out the details of the data, I decided to read them in order.  \n",
    "This allows to easily plot a stroke for each digit (see plot_digit strokes() below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strokes = []\n",
    "for i in range(0,10):\n",
    "    filename = \"magic_wand_digit_data/petewarden_{:d}.json\".format(i)\n",
    "    with open(filename, \"r\") as file:\n",
    "        file_contents = file.read()           # reads the file into a string\n",
    "    file_data = json.loads(file_contents)     # converts the json string into a Python dictionary\n",
    "    for stroke in file_data[\"strokes\"]:       # append the filename from which the stroke is coming\n",
    "        stroke[\"filename\"] = filename\n",
    "        strokes.append(stroke)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No of strokes: \",len(strokes))\n",
    "print(\"Type of strokes: \",type(strokes))\n",
    "print(\"Type of strokes[0]:\", type(strokes[0]))\n",
    "print(strokes[0])\n",
    "for i in range(10):\n",
    "    print(\"stroke length of stroke {:d}: {:d}\".format(i,len(strokes[i]['strokePoints'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stroke length depends on the speed at which the stroke is executed. As we see above, it is variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plots the strokes. Strokes are given by individual points in space, which are connected through lines in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xfLzrpyLVJ5S"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_stroke(stroke):\n",
    "\n",
    "  x_array = []\n",
    "  y_array = []\n",
    "  for coords in stroke[\"strokePoints\"]:\n",
    "    x_array.append(coords[\"x\"])\n",
    "    y_array.append(coords[\"y\"])\n",
    "\n",
    "  fig = plt.figure(figsize=(12.8, 4.8))\n",
    "  # fig.suptitle(\"Label: {:s}\".format(stroke[\"label\"]))\n",
    "\n",
    "  ax = fig.add_subplot(131)\n",
    "  ax.set_title(\"Label: {:s}\".format(stroke[\"label\"]))\n",
    "  ax.set_xlabel('x')\n",
    "  ax.set_ylabel('y')\n",
    "  ax.set_xlim(-0.5, 0.5)\n",
    "  ax.set_ylim(-0.5, 0.5)\n",
    "  ax.plot(x_array, y_array)\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "dveZd2ZuW-jl",
    "outputId": "df5428b1-af03-4ad7-f6fa-0cafdf0cb727"
   },
   "outputs": [],
   "source": [
    "plot_stroke(strokes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the digits save one example in a strokes file. These will allow to test the transmission to the WEB server\n",
    "via BlueTooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveStrokes():\n",
    "     for i in range(10):\n",
    "        x_array = []\n",
    "        y_array = []\n",
    "        stroke = strokes[i*100]\n",
    "        for coords in stroke[\"strokePoints\"]:\n",
    "            x_array.append(coords[\"x\"])\n",
    "            y_array.append(coords[\"y\"])\n",
    "        filename = \"strokes/digit_{:d}.txt\".format(i)\n",
    "        print(\"Writing strokes file: \" + filename)\n",
    "        strokeFile = open(filename,\"w\")\n",
    "        for j in range(len(x_array)):\n",
    "            x = \"{:6.4f} \".format(x_array[j])\n",
    "            y = \"{:6.4f}\\n\".format(y_array[j])                          \n",
    "            strokeFile.write(x)\n",
    "            strokeFile.write(y)\n",
    "        strokeFile.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveStrokes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_digit_strokes():\n",
    "    fig, axs = plt.subplots(5,2,figsize=(8, 15))\n",
    "    fig.suptitle(\"The 10 different digit strokes\",y=1.0)\n",
    "\n",
    "    for i in range(10):\n",
    "        x_array = []\n",
    "        y_array = []\n",
    "        stroke = strokes[i*100]\n",
    "        for coords in stroke[\"strokePoints\"]:\n",
    "            x_array.append(coords[\"x\"])\n",
    "            y_array.append(coords[\"y\"])\n",
    "\n",
    "        if i < 5:\n",
    "            l = 0\n",
    "            k = i\n",
    "        else:\n",
    "            l = 1\n",
    "            k = i-5\n",
    "            \n",
    "        axs[k,l].set_title(\"Label: {:s}\".format(stroke[\"label\"]))\n",
    "        axs[k,l].set_xlabel('x')\n",
    "        axs[k,l].set_ylabel('y')\n",
    "        axs[k,l].set_xlim(-0.5, 0.5)\n",
    "        axs[k,l].set_ylim(-0.5, 0.5)\n",
    "        axs[k,l].plot(x_array, y_array)\n",
    "        \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_digit_strokes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to have the digits as a pixel image the strokes must be rasterized. \n",
    "This means that we must determine the pixels in an image from the strokes.  \n",
    "This results in rgb colored pixels, where the color indicates the movement direction starting from red and ending in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3FVPj-eqjvoB"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "FIXED_POINT = 256\n",
    "\n",
    "def mul_fp(a, b):\n",
    "  return (a * b) / FIXED_POINT\n",
    "\n",
    "def div_fp(a, b):\n",
    "  if b == 0:\n",
    "    b = 1\n",
    "  return (a * FIXED_POINT) / b\n",
    "\n",
    "def float_to_fp(a):\n",
    "  return math.floor(a * FIXED_POINT)\n",
    "\n",
    "def norm_to_coord_fp(a, range_fp, half_size_fp):\n",
    "  a_fp = float_to_fp(a)\n",
    "  norm_fp = div_fp(a_fp, range_fp)\n",
    "  return mul_fp(norm_fp, half_size_fp) + half_size_fp\n",
    "\n",
    "def round_fp_to_int(a):\n",
    "  return math.floor((a + (FIXED_POINT / 2)) / FIXED_POINT)\n",
    "\n",
    "def gate(a, min, max):\n",
    "  if a < min:\n",
    "    return min\n",
    "  elif a > max:\n",
    "    return max\n",
    "  else:\n",
    "    return a\n",
    "\n",
    "def rasterize_stroke(stroke_points, x_range, y_range, width, height):\n",
    "  num_channels = 3\n",
    "  buffer_byte_count = height * width * num_channels\n",
    "  buffer = bytearray(buffer_byte_count)\n",
    "\n",
    "  width_fp = width * FIXED_POINT\n",
    "  height_fp = height * FIXED_POINT\n",
    "  half_width_fp = width_fp / 2\n",
    "  half_height_fp = height_fp / 2\n",
    "  x_range_fp = float_to_fp(x_range)\n",
    "  y_range_fp = float_to_fp(y_range)\n",
    "\n",
    "  t_inc_fp = FIXED_POINT / len(stroke_points)\n",
    "\n",
    "  one_half_fp = (FIXED_POINT / 2)\n",
    "  for i in range(15):\n",
    "      print(\"i, x, y: \", i, stroke_points[i][\"x\"],stroke_points[i][\"y\"])\n",
    "  print(\"width, height, width_fp, height_fp: \",width, height, width_fp, height_fp)\n",
    "  print(\"x_range, y_range, x_range_fp, y_range_fp: \",x_range, y_range, x_range_fp, y_range_fp)\n",
    "\n",
    "  # Go through all the stroke points and extract the start x,y, end x,y and the distance in x and y\n",
    "  # The start point is the point at the current point index, end point is the next point\n",
    "\n",
    "  for point_index in range(len(stroke_points) - 1):\n",
    "    start_point = stroke_points[point_index]\n",
    "    end_point = stroke_points[point_index + 1]\n",
    "    start_x_fp = norm_to_coord_fp(start_point[\"x\"], x_range_fp, half_width_fp)\n",
    "    start_y_fp = norm_to_coord_fp(-start_point[\"y\"], y_range_fp, half_height_fp)\n",
    "    end_x_fp = norm_to_coord_fp(end_point[\"x\"], x_range_fp, half_width_fp)\n",
    "    end_y_fp = norm_to_coord_fp(-end_point[\"y\"], y_range_fp, half_height_fp)\n",
    "    delta_x_fp = end_x_fp - start_x_fp\n",
    "    delta_y_fp = end_y_fp - start_y_fp\n",
    "    t_fp = point_index * t_inc_fp\n",
    "      \n",
    "    if (point_index == 0):\n",
    "      print(\"start_point x,y:\", start_point[\"x\"], start_point[\"y\"])\n",
    "      print(\"end_point x,y:\", end_point[\"x\"], end_point[\"y\"])        \n",
    "      print(\"start_x_fp, start_y_fp, end_x_fp, end_y_fp: \",start_x_fp, start_y_fp, end_x_fp, end_y_fp)\n",
    "      print(\"length of stroke, t_inc_fp, t_fp: \",len(stroke_points),t_inc_fp, t_fp)\n",
    "    \n",
    "    if t_fp < one_half_fp:\n",
    "      local_t_fp = div_fp(t_fp, one_half_fp)\n",
    "      one_minus_t_fp = FIXED_POINT - local_t_fp\n",
    "      red = round_fp_to_int(one_minus_t_fp * 255)\n",
    "      green = round_fp_to_int(local_t_fp * 255)\n",
    "      blue = 0\n",
    "    else:\n",
    "      local_t_fp = div_fp(t_fp - one_half_fp, one_half_fp)\n",
    "      one_minus_t_fp = FIXED_POINT - local_t_fp\n",
    "      red = 0\n",
    "      green = round_fp_to_int(one_minus_t_fp * 255)\n",
    "      blue = round_fp_to_int(local_t_fp * 255)\n",
    "        \n",
    "    red = gate(red, 0, 255)\n",
    "    green = gate(green, 0, 255)\n",
    "    blue = gate(blue, 0, 255)\n",
    "\n",
    "    if (point_index == 0):\n",
    "      print(\"red,green,blue: \",red, green, blue)\n",
    "\n",
    "    if abs(delta_x_fp) > abs(delta_y_fp):\n",
    "      line_length = abs(round_fp_to_int(delta_x_fp))\n",
    "      if delta_x_fp > 0:\n",
    "        x_inc_fp = 1 * FIXED_POINT\n",
    "        y_inc_fp = div_fp(delta_y_fp, delta_x_fp)\n",
    "      else:\n",
    "        x_inc_fp = -1 * FIXED_POINT\n",
    "        y_inc_fp = -div_fp(delta_y_fp, delta_x_fp)\n",
    "    else:\n",
    "      line_length = abs(round_fp_to_int(delta_y_fp))\n",
    "      if delta_y_fp > 0:\n",
    "        y_inc_fp = 1 * FIXED_POINT\n",
    "        x_inc_fp = div_fp(delta_x_fp, delta_y_fp)\n",
    "      else:\n",
    "        y_inc_fp = -1 * FIXED_POINT\n",
    "        x_inc_fp = -div_fp(delta_x_fp, delta_y_fp)\n",
    "    for i in range(line_length + 1):\n",
    "      x_fp = start_x_fp + (i * x_inc_fp)\n",
    "      y_fp = start_y_fp + (i * y_inc_fp)\n",
    "      x = round_fp_to_int(x_fp)\n",
    "      y = round_fp_to_int(y_fp)\n",
    "      if (x < 0) or (x >= width) or (y < 0) or (y >= height):\n",
    "        continue\n",
    "      buffer_index = (y * width * num_channels) + (x * num_channels)\n",
    "      buffer[buffer_index + 0] = red\n",
    "      buffer[buffer_index + 1] = green\n",
    "      buffer[buffer_index + 2] = blue\n",
    "  \n",
    "  np_buffer = np.frombuffer(buffer, dtype=np.uint8).reshape(height, width, num_channels)\n",
    "\n",
    "  return np_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "id": "sOaxOIjRskJg",
    "outputId": "ac2b4c02-1a39-4be8-bb7b-41930ed133b1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raster = rasterize_stroke(strokes[400][\"strokePoints\"], 0.5, 0.5, 32, 32)\n",
    "print(\"length of raster: \",len(raster))\n",
    "print(\"raster shape: \",raster.shape)\n",
    "PIL.Image.fromarray(raster).resize((512, 512), PIL.Image.NEAREST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save an image for each digit in binary format to be used on the ESP32 for model testing in the folder bin_images.  \n",
    "Save it also as a png file in the folder png_files.  \n",
    "We can use either of the two formats to evalute the model performance on the PC. See the evaluate.ipynb notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    raster = rasterize_stroke(strokes[i*100][\"strokePoints\"], 0.5, 0.5, 32, 32)\n",
    "    print(\"filename: digit_{:d}.bin\".format(i))\n",
    "    with open(\"bin_images/digit_{:d}.bin\".format(i),'bw+') as f:\n",
    "        f.write(raster)\n",
    "    f.close()\n",
    "    image = PIL.Image.fromarray(raster)\n",
    "    image.save(\"png_files/digit_{:d}.png\".format(i))\n",
    "    print(\"data type of raster pixels: \",raster.dtype,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o-FOVdFpgkdf"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "X_RANGE = 0.6\n",
    "Y_RANGE = 0.6\n",
    "\n",
    "def ensure_empty_dir(dirname):\n",
    "  dirpath = Path(dirname)\n",
    "  if dirpath.exists() and dirpath.is_dir():\n",
    "    shutil.rmtree(dirpath)\n",
    "  dirpath.mkdir()\n",
    "\n",
    "def augment_points(points, move_range, scale_range, rotate_range):\n",
    "  move_x = np.random.uniform(low=-move_range, high=move_range)\n",
    "  move_y = np.random.uniform(low=-move_range, high=move_range)\n",
    "  scale = np.random.uniform(low=1.0-scale_range, high=1.0+scale_range)\n",
    "  rotate = np.random.uniform(low=-rotate_range, high=rotate_range)\n",
    "\n",
    "  x_axis_x = math.cos(rotate) * scale\n",
    "  x_axis_y = math.sin(rotate) * scale\n",
    "\n",
    "  y_axis_x = -math.sin(rotate) * scale\n",
    "  y_axis_y = math.cos(rotate) * scale\n",
    "\n",
    "  new_points = []\n",
    "  for point in points:\n",
    "    old_x = point[\"x\"]\n",
    "    old_y = point[\"y\"]\n",
    "    new_x = (x_axis_x * old_x) + (x_axis_y * old_y) + move_x\n",
    "    new_y = (y_axis_x * old_x) + (y_axis_y * old_y) + move_y\n",
    "    new_points.append({\"x\": new_x, \"y\": new_y})\n",
    "\n",
    "  return new_points\n",
    "\n",
    "def save_strokes_as_images(strokes, root_folder, width, height, augment_count):\n",
    "  ensure_empty_dir(root_folder)\n",
    "  labels = set()\n",
    "  for stroke in strokes:\n",
    "    labels.add(stroke[\"label\"].lower())\n",
    "  for label in labels:\n",
    "    label_path = Path(root_folder, label)\n",
    "    ensure_empty_dir(label_path)\n",
    "\n",
    "  label_counts = {}\n",
    "  for stroke in strokes:\n",
    "    points = stroke[\"strokePoints\"]\n",
    "    label = stroke[\"label\"].lower()\n",
    "    if label == \"\":\n",
    "      raise Exception(\"Missing label for %s:%d\" % (stroke[\"filename\"], stroke[\"index\"]))\n",
    "    if label not in label_counts:\n",
    "      label_counts[label] = 0\n",
    "    label_count = label_counts[label]\n",
    "    label_counts[label] += 1\n",
    "    raster = rasterize_stroke(points, X_RANGE, Y_RANGE, width, height)\n",
    "    image = PIL.Image.fromarray(raster)\n",
    "    image.save(Path(root_folder, label, str(label_count) + \".png\"))\n",
    "    for i in range(augment_count):\n",
    "      augmented_points = augment_points(points, 0.1, 0.1, 0.3)\n",
    "      raster = rasterize_stroke(augmented_points, X_RANGE, Y_RANGE, width, height)\n",
    "      image = PIL.Image.fromarray(raster)\n",
    "      image.save(Path(root_folder, label, str(label_count) + \"_a\" + str(i) + \".png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2cmmhBwW9d_p"
   },
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 32\n",
    "IMAGE_HEIGHT = 32\n",
    "\n",
    "shuffled_strokes = strokes\n",
    "np.random.shuffle(shuffled_strokes)\n",
    "\n",
    "test_percentage = 10\n",
    "validation_percentage = 10\n",
    "train_percentage = 100 - (test_percentage + validation_percentage)\n",
    "\n",
    "test_count = math.floor((len(shuffled_strokes) * test_percentage) / 100)\n",
    "validation_count = math.floor((len(shuffled_strokes) * validation_percentage) / 100)\n",
    "test_strokes = shuffled_strokes[0:test_count]\n",
    "validation_strokes = shuffled_strokes[test_count:(test_count + validation_count)]\n",
    "train_strokes = shuffled_strokes[(test_count + validation_count):]\n",
    "\n",
    "save_strokes_as_images(test_strokes, \"test\", IMAGE_WIDTH, IMAGE_HEIGHT, 10)\n",
    "save_strokes_as_images(validation_strokes, \"validation\", IMAGE_WIDTH, IMAGE_HEIGHT, 0)\n",
    "save_strokes_as_images(train_strokes, \"train\", IMAGE_WIDTH, IMAGE_HEIGHT, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9-Ttfz7LlPil",
    "outputId": "920681dc-fc77-4c8e-aeb9-bdb759470871"
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "validation_ds = image_dataset_from_directory(\n",
    "    directory='validation',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=32,\n",
    "    image_size=(IMAGE_WIDTH, IMAGE_HEIGHT)).prefetch(buffer_size=32)\n",
    "\n",
    "train_ds = image_dataset_from_directory(\n",
    "    directory='train',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=32,\n",
    "    image_size=(IMAGE_WIDTH, IMAGE_HEIGHT)).prefetch(buffer_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "id": "Q_vUMVmQn400",
    "outputId": "847d6621-4031-480c-f974-711df6a40aae"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21qi3bLAo80t"
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = layers.Conv2D(16, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    activation = \"softmax\"\n",
    "    units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7DjpCkt0qZiy",
    "outputId": "fe3d7104-57e9-4e08-ce74-8648225267cb"
   },
   "outputs": [],
   "source": [
    "model = make_model(input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3), num_classes=10)\n",
    "model.summary()\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "287Am2coqkQC",
    "outputId": "8d2771fa-86e0-41d4-a3cd-ace1975fcd13"
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"checkpoints/save_at_{epoch}.keras\"),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "history = model.fit(\n",
    "    train_ds, epochs=epochs, callbacks=callbacks, validation_data=validation_ds,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1,len(history.history['loss'])+1)\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs,loss,'g.',label='loss')\n",
    "plt.plot(epochs,val_loss,'b.',label='validation loss')\n",
    "plt.title('Loss and validation loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs,accuracy,'g.',label='accuracy')\n",
    "plt.plot(epochs,val_accuracy,'b.',label='validation accuracy')\n",
    "plt.title('Accuracy and validation accuray')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ocE3kudZq24U",
    "outputId": "b648723c-1321-4178-f6a9-7126cfb9a33e"
   },
   "outputs": [],
   "source": [
    "def predict_image(model, filename):\n",
    "  img = keras.preprocessing.image.load_img(filename, target_size=(IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "  img_array = keras.preprocessing.image.img_to_array(img)\n",
    "  img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "  predictions = model.predict(img_array).flatten()\n",
    "  predicted_label_index = np.argmax(predictions)\n",
    "  predicted_score = predictions[predicted_label_index]\n",
    "  return (predicted_label_index, predicted_score)\n",
    "  \n",
    "index, score = predict_image(model, \"test/7/2.png\")\n",
    "\n",
    "print(index, score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MYyLaqOYtxTH",
    "outputId": "766a130b-53a7-4230-b685-6de0d8d66aa3"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import glob\n",
    "\n",
    "SCORE_THRESHOLD = 0.75\n",
    "\n",
    "correct_count = 0\n",
    "wrong_count = 0\n",
    "discarded_count = 0\n",
    "for label_dir in glob.glob(\"test/*\"):\n",
    "  label = int(label_dir.replace(\"test/\", \"\"))\n",
    "  for filename in glob.glob(label_dir + \"/*.png\"):\n",
    "    index, score = predict_image(model, filename)\n",
    "    if score < SCORE_THRESHOLD:\n",
    "      discarded_count += 1\n",
    "      continue\n",
    "    if index == label:\n",
    "      correct_count += 1\n",
    "    else:\n",
    "      wrong_count += 1\n",
    "      print(\"%d expected, %d found with score %f\" % (label, index, score))\n",
    "      display(Image(filename=filename))\n",
    "\n",
    "correct_percentage = (correct_count / (correct_count + wrong_count)) * 100\n",
    "print(\"%.1f%% correct (N=%d, %d unknown)\" % (correct_percentage, (correct_count + wrong_count), discarded_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d26wGJn0t20g",
    "outputId": "b5971e8e-c630-487d-d7ab-b4a4c99aa1a2"
   },
   "outputs": [],
   "source": [
    "model.save(SAVED_MODEL_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ki3E7lM_Kr0C",
    "outputId": "038624f6-ba40-4e7a-9474-dbdd75940d90"
   },
   "outputs": [],
   "source": [
    "#!curl -L https://storage.googleapis.com/download.tensorflow.org/models/tflite/micro/magic_wand_saved_model_2021_01_02.tgz -o saved_model.tgz\n",
    "#!tar -xzf saved_model.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t-hU8aU24gbL",
    "outputId": "11d2ecc2-509a-46b8-ab02-15e17310b48b"
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL_FILENAME)\n",
    "model_no_quant_tflite = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(FLOAT_TFL_MODEL_FILENAME, \"wb\").write(model_no_quant_tflite)\n",
    "\n",
    "def representative_dataset():\n",
    "  for filename in glob.glob(\"test/*/*.png\"):\n",
    "    img = keras.preprocessing.image.load_img(filename, target_size=(IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "    img_array = keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Create batch axis      for images, labels in train_ds.take(1):\n",
    "    yield([img_array])\n",
    "# Set the optimization flag.\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# Enforce integer only quantization\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "# Provide a representative dataset to ensure we quantize correctly.\n",
    "converter.representative_dataset = representative_dataset\n",
    "model_tflite = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(QUANTIZED_TFL_MODEL_FILENAME, \"wb\").write(model_tflite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w5QZTfwRLFAi"
   },
   "outputs": [],
   "source": [
    "def predict_tflite(tflite_model, filename):\n",
    "  img = keras.preprocessing.image.load_img(filename, target_size=(IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "  img_array = keras.preprocessing.image.img_to_array(img)\n",
    "  img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "  # Initialize the TFLite interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  print(\"Input details:\")\n",
    "  print(input_details)\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "  print(\"Output_details: \")\n",
    "  print(output_details)\n",
    "\n",
    "  # If required, quantize the input layer (from float to integer)\n",
    "  input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "  if (input_scale, input_zero_point) != (0.0, 0):\n",
    "    img_array = np.multiply(img_array, 1.0 / input_scale) + input_zero_point\n",
    "    img_array = img_array.astype(input_details[\"dtype\"])\n",
    "\n",
    "  # Invoke the interpreter\n",
    "  interpreter.set_tensor(input_details[\"index\"], img_array)\n",
    "  interpreter.invoke()\n",
    "  pred = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "  \n",
    "  # If required, dequantized the output layer (from integer to float)\n",
    "  output_scale, output_zero_point = output_details[\"quantization\"]\n",
    "  if (output_scale, output_zero_point) != (0.0, 0):\n",
    "    pred = pred.astype(np.float32)\n",
    "    pred = np.multiply((pred - output_zero_point), output_scale)\n",
    "  \n",
    "  predicted_label_index = np.argmax(pred)\n",
    "  predicted_score = pred[predicted_label_index]\n",
    "  return (predicted_label_index, predicted_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vtee_WxPMgup",
    "outputId": "e27400e5-de03-4b5f-864f-8ecf240a4d39"
   },
   "outputs": [],
   "source": [
    "predict_tflite(model_no_quant_tflite, \"test/7/2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0rp0LirfN9vB",
    "outputId": "3272e677-7489-461c-bbd1-5fca6ab93b4e"
   },
   "outputs": [],
   "source": [
    "predict_tflite(model_tflite, \"test/7/2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jdNgTO19PRqO",
    "outputId": "26dd3095-4f6e-40b8-eb6a-1cb0cb21d514"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "correct_count = 0\n",
    "wrong_count = 0\n",
    "discarded_count = 0\n",
    "for label_dir in glob.glob(\"test/*\"):\n",
    "  label = int(label_dir.replace(\"test/\", \"\"))\n",
    "  for filename in glob.glob(label_dir + \"/*.png\"):\n",
    "    index, score = predict_tflite(model_tflite, filename)\n",
    "    if score < 0.75:\n",
    "      discarded_count += 1\n",
    "      continue\n",
    "    if index == label:\n",
    "      correct_count += 1\n",
    "    else:\n",
    "      wrong_count += 1\n",
    "      print(\"%d expected, %d found with score %f\" % (label, index, score))\n",
    "      display(Image(filename=filename))\n",
    "\n",
    "correct_percentage = (correct_count / (correct_count + wrong_count)) * 100\n",
    "\n",
    "print(\"%.1f%% correct (N=%d, %d unknown)\" % (correct_percentage, (correct_count + wrong_count), discarded_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "NTjGMU8BPpoz",
    "outputId": "fcd585d8-7e97-4f4a-a623-160e74b0505e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_dir_size(dir):\n",
    "  size = 0\n",
    "  for f in os.scandir(dir):\n",
    "    if f.is_file():\n",
    "      size += f.stat().st_size\n",
    "    elif f.is_dir():\n",
    "      size += get_dir_size(f.path)\n",
    "  return size\n",
    "\n",
    "# Calculate size\n",
    "size_tf = get_dir_size(SAVED_MODEL_FILENAME)\n",
    "size_no_quant_tflite = os.path.getsize(FLOAT_TFL_MODEL_FILENAME)\n",
    "size_tflite = os.path.getsize(QUANTIZED_TFL_MODEL_FILENAME)\n",
    "\n",
    "# Compare size\n",
    "pd.DataFrame.from_records(\n",
    "    [[\"TensorFlow\", f\"{size_tf} bytes\", \"\"],\n",
    "     [\"TensorFlow Lite\", f\"{size_no_quant_tflite} bytes \", f\"(reduced by {size_tf - size_no_quant_tflite} bytes)\"],\n",
    "     [\"TensorFlow Lite Quantized\", f\"{size_tflite} bytes\", f\"(reduced by {size_no_quant_tflite - size_tflite} bytes)\"]],\n",
    "     columns = [\"Model\", \"Size\", \"\"], index=\"Model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mrvnEJLfR8KU",
    "outputId": "df0c61f6-0a4a-4792-e08a-eef095f820e9"
   },
   "outputs": [],
   "source": [
    "# Install xxd if it is not available\n",
    "# !apt-get update && apt-get -qq install xxd   # This is already installed\n",
    "# Convert to a C source file, i.e, a TensorFlow Lite for Microcontrollers model\n",
    "!xxd -i {QUANTIZED_TFL_MODEL_FILENAME} > {TFL_CC_MODEL_FILENAME}\n",
    "# Update variable names\n",
    "REPLACE_TEXT = QUANTIZED_TFL_MODEL_FILENAME.replace('/', '_').replace('.', '_')\n",
    "!sed -i 's/'{REPLACE_TEXT}'/g_magic_wand_model_data/g' {TFL_CC_MODEL_FILENAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oazLUtBqWzdJ",
    "outputId": "5e50b68f-b3b9-4d60-b454-a2d75c16572c"
   },
   "outputs": [],
   "source": [
    "# Print the C source file\n",
    "!tail {TFL_CC_MODEL_FILENAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VqN2F42PW-uv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Magic Wand Training",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
