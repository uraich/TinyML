{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91d793e7-9446-44a7-8322-e69b4e94f1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 21:24:25.122944: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12532f5-0916-4c08-80fc-60eda5fe5f97",
   "metadata": {},
   "source": [
    "allocate on the GPU only the memory that is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b1af60-6b13-43bb-828b-22a139cb3b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ed85c00-75e0-424b-804e-53b1369304fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Disable all GPUS\n",
    "    tf.config.set_visible_devices([], 'GPU')\n",
    "    visible_devices = tf.config.get_visible_devices()\n",
    "    for device in visible_devices:\n",
    "        assert device.device_type != 'GPU'\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dca8abd1-bc28-4679-9d15-9a54428e421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(units=20):\n",
    "  \"\"\"Create a keras LSTM model for MNIST recognition\n",
    "\n",
    "    Args:\n",
    "        units (int, optional): dimensionality of the output space for the model.\n",
    "          Defaults to 20.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: A Keras LSTM model\n",
    "    \"\"\"\n",
    "\n",
    "  model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Input(shape=(28, 28), name=\"input\"),\n",
    "      tf.keras.layers.LSTM(units, return_sequences=True),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(10, activation=tf.nn.softmax, name=\"output\")\n",
    "  ])\n",
    "  model.compile(optimizer=\"adam\",\n",
    "                loss=\"sparse_categorical_crossentropy\",\n",
    "                metrics=[\"accuracy\"])\n",
    "  model.summary()\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddd59f7b-b793-4f38-a6dc-b126d841c810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data():\n",
    "  \"\"\"Get MNIST train and test data\n",
    "\n",
    "    Returns:\n",
    "        tuple: (data, label) pairs for train and test\n",
    "    \"\"\"\n",
    "  (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
    "  x_train = x_train / 255.  # normalize pixel values to 0-1\n",
    "  x_train = x_train.astype(np.float32)\n",
    "  return (x_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7367cb7-4be0-4a51-96f0-6533d60f6141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm_model(epochs, x_train, y_train):\n",
    "  \"\"\"Train keras LSTM model on MNIST dataset\n",
    "\n",
    "    Args: epochs (int) : number of epochs to train the model\n",
    "        x_train (numpy.array): list of the training data\n",
    "        y_train (numpy.array): list of the corresponding array\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: A trained keras LSTM model\n",
    "  \"\"\"\n",
    "  model = create_model()\n",
    "  callback = tf.keras.callbacks.EarlyStopping(\n",
    "      monitor=\"val_loss\",\n",
    "      patience=3)  #early stop if validation loss does not drop anymore\n",
    "  model.fit(x_train,\n",
    "            y_train,\n",
    "            epochs=epochs,\n",
    "            validation_split=0.2,\n",
    "            batch_size=32,\n",
    "            callbacks=[callback])\n",
    "  return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55be154b-2f07-442c-b5c5-a7f477a7019e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_quantized_tflite_model(model, x_train):\n",
    "  \"\"\"Convert the save TF model to tflite model, then save it as .tflite flatbuffer format\n",
    "\n",
    "    See\n",
    "    https://www.tensorflow.org/lite/performance/post_training_integer_quant#convert_using_integer-only_quantization\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): the trained LSTM Model\n",
    "        x_train (numpy.array): list of the training data\n",
    "\n",
    "    Returns:\n",
    "        The converted model in serialized format.\n",
    "  \"\"\"\n",
    "\n",
    "  def representative_dataset_gen(num_samples=100):\n",
    "    for data in x_train[:num_samples]:\n",
    "      yield [data.reshape(1, 28, 28)]\n",
    "\n",
    "  converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "  converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "  converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "  converter.inference_input_type = tf.int8\n",
    "  converter.inference_output_type = tf.int8\n",
    "  converter.representative_dataset = representative_dataset_gen\n",
    "  tflite_model = converter.convert()\n",
    "  return tflite_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2878299-32e7-4ca5-ada7-baaf8f3a4942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tflite_model(model):\n",
    "  \"\"\"Convert the save TF model to tflite model, then save it as .tflite flatbuffer format\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): the trained LSTM Model\n",
    "\n",
    "    Returns:\n",
    "        The converted model in serialized format.\n",
    "  \"\"\"\n",
    "  converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "  tflite_model = converter.convert()\n",
    "  return tflite_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd3653a0-10fc-46e8-8d18-ed11fbcc324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tflite_model(tflite_model, save_dir, model_name):\n",
    "  \"\"\"save the converted tflite model\n",
    "\n",
    "  Args:\n",
    "      tflite_model (binary): the converted model in serialized format.\n",
    "      save_dir (str): the save directory\n",
    "      model_name (str): model name to be saved\n",
    "  \"\"\"\n",
    "  if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "  save_path = os.path.join(save_dir, model_name)\n",
    "  with open(save_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "  print(\"Tflite model saved to %s\", save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd630d58-6693-41e0-95e6-ed9113445695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_trained_model(trained_model):\n",
    "  \"\"\"Fix the input of the trained model for inference\n",
    "\n",
    "    Args:\n",
    "        trained_model (tf.keras.Model): the trained LSTM model\n",
    "\n",
    "    Returns:\n",
    "        run_model (tf.keras.Model): the trained model with fixed input tensor size for inference\n",
    "  \"\"\"\n",
    "  # TFLite converter requires fixed shape input to work, alternative: b/225231544\n",
    "  fixed_input = tf.keras.layers.Input(shape=[28, 28],\n",
    "                                      batch_size=1,\n",
    "                                      dtype=trained_model.inputs[0].dtype,\n",
    "                                      name=\"fixed_input\")\n",
    "  fixed_output = trained_model(fixed_input)\n",
    "  run_model = tf.keras.models.Model(fixed_input, fixed_output)\n",
    "  return run_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f68d6c-0d8d-4d4c-80d9-ec280295032d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc5d6849-398e-40ed-a04b-d4b23b7322a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8672af87-f2a7-43d1-a361-236a5dce1e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 28, 20)            3920      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 560)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                5610      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9530 (37.23 KB)\n",
      "Trainable params: 9530 (37.23 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 21:24:33.767796: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbf8c00c510 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-09-26 21:24:33.767840: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-09-26 21:24:34.165849: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  13/1500 [..............................] - ETA: 13s - loss: 2.2115 - accuracy: 0.2308   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 21:24:34.849979: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 18s 10ms/step - loss: 0.3744 - accuracy: 0.8881 - val_loss: 0.1578 - val_accuracy: 0.9542\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1360 - accuracy: 0.9586 - val_loss: 0.1172 - val_accuracy: 0.9669\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1008 - accuracy: 0.9682 - val_loss: 0.0956 - val_accuracy: 0.9722\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 14s 10ms/step - loss: 0.0822 - accuracy: 0.9746 - val_loss: 0.0834 - val_accuracy: 0.9749\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0702 - accuracy: 0.9784 - val_loss: 0.0868 - val_accuracy: 0.9742\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 14s 10ms/step - loss: 0.0630 - accuracy: 0.9804 - val_loss: 0.0742 - val_accuracy: 0.9782\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0560 - accuracy: 0.9821 - val_loss: 0.0716 - val_accuracy: 0.9775\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 16s 11ms/step - loss: 0.0508 - accuracy: 0.9837 - val_loss: 0.0641 - val_accuracy: 0.9787\n",
      "Epoch 9/20\n",
      "1500/1500 [==============================] - 16s 10ms/step - loss: 0.0468 - accuracy: 0.9849 - val_loss: 0.0653 - val_accuracy: 0.9790\n",
      "Epoch 10/20\n",
      "1500/1500 [==============================] - 16s 10ms/step - loss: 0.0430 - accuracy: 0.9861 - val_loss: 0.0663 - val_accuracy: 0.9791\n",
      "Epoch 11/20\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0393 - accuracy: 0.9873 - val_loss: 0.0616 - val_accuracy: 0.9801\n",
      "Epoch 12/20\n",
      "1500/1500 [==============================] - 14s 10ms/step - loss: 0.0373 - accuracy: 0.9886 - val_loss: 0.0609 - val_accuracy: 0.9817\n",
      "Epoch 13/20\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0355 - accuracy: 0.9882 - val_loss: 0.0607 - val_accuracy: 0.9811\n",
      "Epoch 14/20\n",
      "1500/1500 [==============================] - 14s 10ms/step - loss: 0.0321 - accuracy: 0.9896 - val_loss: 0.0634 - val_accuracy: 0.9812\n",
      "Epoch 15/20\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0317 - accuracy: 0.9895 - val_loss: 0.0606 - val_accuracy: 0.9810\n",
      "Epoch 16/20\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0284 - accuracy: 0.9911 - val_loss: 0.0634 - val_accuracy: 0.9824\n",
      "Epoch 17/20\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0274 - accuracy: 0.9916 - val_loss: 0.0598 - val_accuracy: 0.9822\n",
      "Epoch 18/20\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 0.0553 - val_accuracy: 0.9838\n",
      "Epoch 19/20\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0240 - accuracy: 0.9925 - val_loss: 0.0581 - val_accuracy: 0.9829\n",
      "Epoch 20/20\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0237 - accuracy: 0.9919 - val_loss: 0.0676 - val_accuracy: 0.9804\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_lstm_model(20, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1617d75a-3289-42a7-b977-92412a8077a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model = prepare_trained_model(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cd4e588-acc9-48ea-9780-0a54ce0fca55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: models/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF model saved to %s models\n"
     ]
    }
   ],
   "source": [
    "# Save the tf model\n",
    "run_model.save(\"models\", save_format=\"tf\")\n",
    "print(\"TF model saved to %s\", \"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4daa967-f960-4665-8402-42fdacb17614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpgflo2vbn/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpgflo2vbn/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tflite model saved to %s models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 21:36:21.716872: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-09-26 21:36:21.716907: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-09-26 21:36:21.717181: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpgflo2vbn\n",
      "2023-09-26 21:36:21.724170: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2023-09-26 21:36:21.724197: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmpgflo2vbn\n",
      "2023-09-26 21:36:21.749604: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-09-26 21:36:21.831716: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpgflo2vbn\n",
      "2023-09-26 21:36:21.887099: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 169919 microseconds.\n",
      "2023-09-26 21:36:22.066861: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 0.012 M  ops, equivalently 0.006 M  MACs\n"
     ]
    }
   ],
   "source": [
    "tflite_model = convert_tflite_model(run_model)\n",
    "save_tflite_model(tflite_model,\n",
    "                \"models\",\n",
    "                model_name=\"mnist_lstm.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "474d7bb9-2e8f-4445-83ed-a0c181c2458d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmprfsopqmf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmprfsopqmf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tflite model saved to %s models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uli/.virtualenvs/AI/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:887: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2023-09-26 21:37:21.006647: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-09-26 21:37:21.006691: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-09-26 21:37:21.007216: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmprfsopqmf\n",
      "2023-09-26 21:37:21.014373: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2023-09-26 21:37:21.014410: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmprfsopqmf\n",
      "2023-09-26 21:37:21.039720: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-09-26 21:37:21.125011: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmprfsopqmf\n",
      "2023-09-26 21:37:21.189005: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 181802 microseconds.\n",
      "2023-09-26 21:37:21.413834: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 0.012 M  ops, equivalently 0.006 M  MACs\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n",
      "2023-09-26 21:37:21.539224: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 0.012 M  ops, equivalently 0.006 M  MACs\n"
     ]
    }
   ],
   "source": [
    "quantized_tflite_model = convert_quantized_tflite_model(run_model, x_train)\n",
    "save_tflite_model(quantized_tflite_model,\n",
    "                \"models\",\n",
    "                model_name=\"mnist_lstm_quant.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9b1ce6-b7ae-467a-8d6b-fc4bd40f7736",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
