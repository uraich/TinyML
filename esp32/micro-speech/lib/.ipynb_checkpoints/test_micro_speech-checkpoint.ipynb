{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2d56c3f-9dea-43bc-ada1-1163fbfe0298",
   "metadata": {},
   "source": [
    "# Read the example wav file\n",
    "First we decode the file header, then we get at the audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e5ebab8-5544-450a-ac22-6b7d2af0f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_wav_header(audio_buffer):\n",
    "    print(\"-------------------------------------------------------------------------\")\n",
    "    print(\"Show the wav header information\")\n",
    "    print(\"-------------------------------------------------------------------------\")\n",
    "    \n",
    "    riff = audio_buffer[:4].decode()\n",
    "    print(\"File type: {}\".format(riff))\n",
    "\n",
    "    file_size = audio_buffer[7] << 24 | audio_buffer[6] << 16 | audio_buffer[5] << 8 | audio_buffer[4] \n",
    "    print(\"File size: 0x{:d}\".format(file_size))\n",
    "\n",
    "    audio_type = audio_buffer[8:12].decode()\n",
    "    print(\"Audio type: {}\".format(audio_type))\n",
    "\n",
    "    format_marker = audio_buffer[12:15].decode()\n",
    "    print(\"Format marker: {}\".format(format_marker))\n",
    "\n",
    "    data_length = audio_buffer[17] << 8 | audio_buffer[16]\n",
    "    print(\"Data length in bits: {:d}\".format(data_length))\n",
    "\n",
    "    type_format = audio_buffer[21] << 8 | audio_buffer[20]\n",
    "    if type_format == 1:\n",
    "        print(\"PCM - 2 byte integer\")\n",
    "    else:\n",
    "        print(\"Unknown format: {d}\".format(type_format))\n",
    "\n",
    "    no_of_channels = audio_buffer[23] << 8 | audio_buffer[22]\n",
    "    print(\"No of channels: {:d}\".format(no_of_channels))\n",
    "\n",
    "    sample_rate = audio_buffer[27] << 24 | audio_buffer[26] << 16 | audio_buffer[25] << 8 | audio_buffer[24]\n",
    "    print(\"Sample rate: {:d} Hz\".format(sample_rate))\n",
    "\n",
    "    s_rate_bps_ch = audio_buffer[31] << 24 | audio_buffer[30] << 16 | audio_buffer[29] << 8 | audio_buffer[28]\n",
    "    print(\"(Sample rate * Bits per sample * Channels)/8: {:d}\".format(s_rate_bps_ch))\n",
    "\n",
    "    bts_ch = audio_buffer[35] << 8 | audio_buffer[34]\n",
    "    print(\"(Bits per sample * channels)/8: {:d}\".format(bts_ch))\n",
    "\n",
    "    bits_per_sample = audio_buffer[35] << 8 | audio_buffer[34]\n",
    "    print(\"Bits per sample: {:d}\".format(bits_per_sample))\n",
    "\n",
    "    data_section = audio_buffer[36:40].decode()\n",
    "    print(\"Start of data section: {}\".format(data_section))\n",
    "\n",
    "    data_section_length = audio_buffer[43] << 24 | audio_buffer[42] << 16 | audio_buffer[41] << 8 | audio_buffer[40]\n",
    "    print(\"Length of data section: {:d}\".format(data_section_length))\n",
    "    return sample_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70686ac6-68e8-4370-a775-3050ff0d043c",
   "metadata": {},
   "source": [
    "Read the wav file into a buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "063a70bf-55fa-4bb7-8eee-da5e71e8f7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "audiofile = \"yes-example.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1658ea02-8f15-4122-9c9f-ad3c247ef4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    f = open(audiofile,'rb')\n",
    "except:\n",
    "    print(\"Cannot open file {}\".format(audiofile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0f8c2f72-f705-460f-aa56-bf6c73d76b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_buffer = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "03447da8-ce53-470c-bcfb-5dd243fb54f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "Show the wav header information\n",
      "-------------------------------------------------------------------------\n",
      "File type: RIFF\n",
      "File size: 0x32036\n",
      "Audio type: WAVE\n",
      "Format marker: fmt\n",
      "Data length in bits: 16\n",
      "PCM - 2 byte integer\n",
      "No of channels: 1\n",
      "Sample rate: 16000 Hz\n",
      "(Sample rate * Bits per sample * Channels)/8: 32000\n",
      "(Bits per sample * channels)/8: 16\n",
      "Bits per sample: 16\n",
      "Start of data section: data\n",
      "Length of data section: 32000\n"
     ]
    }
   ],
   "source": [
    "kAudioSampleFrequency = decode_wav_header(audio_buffer)\n",
    "kAudioOneMsSize = kAudioSampleFrequency // 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "10ee459e-387f-4875-9343-7948d4acd896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following values are derived from values used during model training.\n",
    "# If you change the way you preprocess the input, update all these constants.\n",
    "kFeatureSliceSize = 40\n",
    "kFeatureSliceCount = 49\n",
    "kFeatureElementCount = (kFeatureSliceSize * kFeatureSliceCount)\n",
    "kFeatureSliceStrideMs = 20\n",
    "kFeatureSliceDurationMs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008d242d-7d7e-4bf5-8e25-6dcfc8f659e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kSilenceIndex = 0\n",
    "kUnknownIndex = 1\n",
    "kYesIndex = 2\n",
    "kNoIndex = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5f271629-7040-4059-a3fa-349df15480c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Window size in samples: 480\n",
      "Stride size in samples: 320\n"
     ]
    }
   ],
   "source": [
    "stride_size = kFeatureSliceStrideMs * kAudioOneMsSize\n",
    "window_size = kFeatureSliceDurationMs * kAudioOneMsSize\n",
    "print(\"\\nWindow size in samples: {:d}\".format(window_size))\n",
    "print(\"Stride size in samples: {:d}\".format(stride_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2f299bf9-49bd-4124-a320-8dc86c4340be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d791a2d1-9d21-4cd2-94ac-8a90a9220467",
   "metadata": {},
   "source": [
    "Convert from bytearray to int16 numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "de957128-24fd-4eae-b874-61045e5d3264",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_array = np.frombuffer(audio_buffer[44:], dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f7603457-3c40-408e-be73-9220ce5174e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of audio samples: 16000\n"
     ]
    }
   ],
   "source": [
    "count = audio_array.size\n",
    "print(\"No of audio samples: {:d}\".format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a1279d28-c2ba-42a4-8241-f6ccb4f1d3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trailing_10ms = np.zeros(160,dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2a41a76f-8186-408a-b178-c6d7064d6a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureData:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.slices=[]\n",
    "        self.totalSlices = 0\n",
    "\n",
    "    def addSlice(self, slice):\n",
    "\n",
    "        self.totalSlices = self.totalSlices + 1\n",
    "        self.slices.append(slice)\n",
    "\n",
    "        if len (self.slices) > 49:\n",
    "            self.slices.pop(0)\n",
    "\n",
    "        # print (\"total slices = %d\\n\" % self.totalSlices)\n",
    "        # print (\"addSlice(): spectrogram length = %d\\n\" % spectrogram.size())\n",
    "        # print (spectrogram)\n",
    "\n",
    "\n",
    "    def setInputTensorValues(self, inputTensor):\n",
    "        # print (inputTensor)\n",
    "        counter = 0\n",
    "        for slice_index in range(len(self.slices)):\n",
    "            slice = self.slices[slice_index]\n",
    "            spectrogram = slice.getSpectrogram()\n",
    "            for spectrogram_index in range (spectrogram.size()):\n",
    "                inputTensor.setValue(counter, spectrogram[spectrogram_index])\n",
    "                counter = counter + 1\n",
    "\n",
    "        # set 1960 values on input tensor\n",
    "        # print (\"set %d values on input tensor\\n\" % (counter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "99878519-2c40-4cff-9ff2-fe214ec438fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Score:\n",
    "    def __init__(self, kind, score):\n",
    "        self.kind = kind\n",
    "        self.score = score\n",
    "        \n",
    "class Results:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.silence_data = []\n",
    "        self.unknown_data = []\n",
    "        self.yes_data = []\n",
    "        self.no_data  = []\n",
    "        self.index = 0\n",
    "\n",
    "    def _computeAverageTotal (self, array_data):\n",
    "        total = 0\n",
    "        array_length = len(array_data)\n",
    "        for i in range (array_length):\n",
    "            total = total + array_data[i]\n",
    "        return math.floor(total / array_length)\n",
    "\n",
    "    def computeResults(self):\n",
    "        topScore = 0\n",
    "        topScoreKind = None\n",
    "        silence = self._computeAverageTotal(self.silence_data)\n",
    "        print(\"Average total of silence: {:d}\".format(silence))\n",
    "\n",
    "        if silence > 200:\n",
    "            topScoreKind = \"silence\"\n",
    "            topScore = silence\n",
    "\n",
    "        unknown = self._computeAverageTotal(self.unknown_data)\n",
    "        print(\"Average total of unknown: {:d}\".format(unknown))\n",
    "\n",
    "        if unknown > topScore and unknown > 200:\n",
    "            topScoreKind = \"unknown\"\n",
    "            topScore = unknown\n",
    "        yes = self._computeAverageTotal(self.yes_data)\n",
    "        print(\"Average total of yes: {:d}\".format(yes))\n",
    "\n",
    "        if yes > topScore and yes > 200:\n",
    "            topScoreKind = \"yes\"\n",
    "            topScore = yes\n",
    "\n",
    "        no = self._computeAverageTotal(self.no_data)\n",
    "        print(\"Average total of no: {:d}\".format(no))\n",
    "\n",
    "        if no > topScore and no > 200:\n",
    "            topScoreKind = \"no\"\n",
    "            topScore = no\n",
    "\n",
    "        return Score (topScoreKind, topScore)\n",
    "\n",
    "    def storeResults(self, silenceScore, unknownScore, yesScore, noScore):\n",
    "        print(\"index: \",self.index)\n",
    "        if self.index == 3:\n",
    "            self.silence_data.pop(0)\n",
    "            self.unknown_data.pop(0)\n",
    "            self.yes_data.pop(0)\n",
    "            self.no_data.pop(0)\n",
    "        else:\n",
    "            self.index += 1\n",
    "\n",
    "        self.silence_data.append(silenceScore)\n",
    "        self.unknown_data.append(unknownScore)\n",
    "        self.yes_data.append(yesScore)\n",
    "        self.no_data.append(noScore)\n",
    "        print(\"Length of silence_data: \",len(self.silence_data), \n",
    "            \"last silence value: {:d}\".format(self.silence_data[len(self.silence_data)-1]))\n",
    "        print(\"Length of unknown_data: \",len(self.unknown_data),\n",
    "             \"last unknown value: {:d}\".format(self.unknown_data[len(self.unknown_data)-1]))            \n",
    "        print(\"Length of yes_data:     \",len(self.yes_data),\n",
    "             \"last yes value: {:d}\".format(self.yes_data[len(self.yes_data)-1]))                    \n",
    "        print(\"Length of no_data:      \",len(self.silence_data),\n",
    "              \"last no value: {:d}\".format(self.no_data[len(self.no_data)-1]))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5dcb2bd5-a519-457c-be6f-4cb1fac8863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 0\n",
    "feature_data = FeatureData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7f1e9b14-e288-42aa-aaaa-f75f13f4d875",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f6f57f22-66f4-439b-96f3-5183f1aca610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:  1\n",
      "Length of silence_data:  2 last silence value: 0\n",
      "Length of unknown_data:  2 last unknown value: 0\n",
      "Length of yes_data:      2 last yes value: 201\n",
      "Length of no_data:       2 last no value: 0\n",
      "Average total of silence: 0\n",
      "Average total of unknown: 0\n",
      "Average total of yes: 201\n",
      "Average total of no: 0\n",
      "kind: yes, score: 201\n"
     ]
    }
   ],
   "source": [
    "r.storeResults(0, 0, 201, 0)\n",
    "score = r.computeResults()\n",
    "print(\"kind: {}, score: {}\".format(score.kind, score.score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7416a2c7-ae96-45b4-b4b3-842ec4187bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:  2\n",
      "Length of silence_data:  3 last silence value: 0\n",
      "Length of unknown_data:  3 last unknown value: 201\n",
      "Length of yes_data:      3 last yes value: 0\n",
      "Length of no_data:       3 last no value: 0\n",
      "Average total of silence: 0\n",
      "Average total of unknown: 67\n",
      "Average total of yes: 134\n",
      "Average total of no: 0\n",
      "kind: None, score: 0\n"
     ]
    }
   ],
   "source": [
    "r.storeResults(0, 201, 0, 0)\n",
    "score = r.computeResults()\n",
    "print(\"kind: {}, score: {}\".format(score.kind, score.score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ba7c3d-3da1-4f4b-86eb-8ec210be319f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a2b75a50-d6a0-466d-b053-d67f75bf211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentAudio(featureData, audio, trailing_10ms):\n",
    "    # In this example we have an array of 1 second of audio data.\n",
    "    # This is a 16,000 element array.\n",
    "   r.storeResults(0, 201, 0, 0)\n",
    "\n",
    "score = r.computeResults() # each micro second is 16 elements in this array.\n",
    "    # the stride is how far over we adjust the start of the window on each step\n",
    "    # in this example it is 20 ms (20x16=320).\n",
    "    # The width of the window for which we capture the spectogram is 30ms (16x30=480).\n",
    "    # this function will turn the input array into a dictionary of start time to wav data\n",
    "\n",
    "    input_audio = np.concatenate((trailing_10ms, audio), axis=0)\n",
    "    input_size = input_audio.size\n",
    "\n",
    "    total_segments = math.floor(input_size / stride_size)\n",
    "    start_index = 0\n",
    "\n",
    "    for segment_index in range (total_segments):\n",
    "        end_index = min (start_index +  window_size, input_size)\n",
    "        print (\"segment_index=%d,start_index=%d, end_index=%d, size=%d\\n\" % (segment_index, start_index, end_index, end_index-start_index))\n",
    "        slice = Slice (input_audio[start_index:end_index], start_index)\n",
    "        featureData.addSlice(slice)\n",
    "        start_index = start_index + stride_size\n",
    "\n",
    "    # return the trailing 10ms\n",
    "    return np.array(input_audio[input_size-160:input_size], dtype=np.int16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4a3319ef-f198-44d3-bca5-987da938a55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segment_index=0,start_index=0, end_index=480, size=480\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Slice' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[136], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m currentEndIndex \u001b[38;5;241m=\u001b[39m currentStartIndex \u001b[38;5;241m+\u001b[39m inputBufferSize\n\u001b[1;32m      8\u001b[0m currentSamples \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(audio_array[currentStartIndex:currentEndIndex], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint16)\n\u001b[0;32m---> 10\u001b[0m trailing_10ms \u001b[38;5;241m=\u001b[39m \u001b[43msegmentAudio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatureData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrentSamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrailing_10ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m start_index \u001b[38;5;241m=\u001b[39m currentEndIndex\n\u001b[1;32m     13\u001b[0m count \u001b[38;5;241m=\u001b[39m count \u001b[38;5;241m-\u001b[39m inputBufferSize\n",
      "Cell \u001b[0;32mIn[81], line 19\u001b[0m, in \u001b[0;36msegmentAudio\u001b[0;34m(featureData, audio, trailing_10ms)\u001b[0m\n\u001b[1;32m     17\u001b[0m end_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m (start_index \u001b[38;5;241m+\u001b[39m  window_size, input_size)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegment_index=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m,start_index=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, end_index=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, size=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (segment_index, start_index, end_index, end_index\u001b[38;5;241m-\u001b[39mstart_index))\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28mslice\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mSlice\u001b[49m (input_audio[start_index:end_index], start_index)\n\u001b[1;32m     20\u001b[0m featureData\u001b[38;5;241m.\u001b[39maddSlice(\u001b[38;5;28mslice\u001b[39m)\n\u001b[1;32m     21\u001b[0m start_index \u001b[38;5;241m=\u001b[39m start_index \u001b[38;5;241m+\u001b[39m stride_size\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Slice' is not defined"
     ]
    }
   ],
   "source": [
    "featureData = FeatureData()\n",
    "inputBufferSize=320*4\n",
    "while count > 0:\n",
    "    # segment the 16000 element array into 320*4 parts\n",
    "    currentStartIndex = start_index\n",
    "    currentEndIndex = currentStartIndex + inputBufferSize\n",
    "\n",
    "    currentSamples = np.array(audio_array[currentStartIndex:currentEndIndex], dtype=np.int16)\n",
    "\n",
    "    trailing_10ms = segmentAudio(featureData, currentSamples, trailing_10ms)\n",
    "\n",
    "    start_index = currentEndIndex\n",
    "    count = count - inputBufferSize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958f5da7-c43a-4846-8664-f33691edea5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
